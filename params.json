{
  "name": "Gsoc-2016",
  "tagline": "Work done in Google Summer of Code 2016 with The Julia Language",
  "body": "# Google Summer of Code 2016\r\n\r\n<sub>[Before the Coding Period](#before-the-coding-period) | [Summary of Contributions](#summary-of-contributions) | [Exposure Correction](#exposure-correction) | [Feature Extraction](#feature-extraction) | [Miscelleanous](#miscellaneous) | [Future Work](#future-work)</sub>\r\n\r\nMy [proposal](https://docs.google.com/document/d/1XD_fpT6YpyK6Iv2Rues2RlU-15l4aBbUZTSz1V216pw/edit?usp=sharing) for this summer was to work on [ImageFeatures.jl](https://github.com/JuliaImages/ImageFeatures.jl), a new Julia package for Feature Extraction and Descriptors in Images. Alongside this, I planned to add Exposure Correction functionality to [Images.jl](https://github.com/timholy/Images.jl), an existing package for Image Processing in Julia.\r\n\r\nAs we reach the final week of GSoC, it feels great to have managed to achieve most of my goals for the summer and gotten the chance to work with amazing people in the [JuliaImages](https://github.com/JuliaImages) organisation as we attempt to develop a full fledged Computer Vision library of which ImageFeatures.jl is an essential part. I hope to continue to work and contribute more packages above and beyond GSoC as we slowly build up the organisation.\r\n\r\nI would like to thank my mentors [Tim Holy](https://github.com/timholy) and [Simon Danisch](https://github.com/SimonDanisch) for helping me out throughout the summer and guiding me towards achieving my goals. Their friendliness and approachability made the summer a enjoyable and fruitful experience.\r\n\r\n## Before the Coding Period\r\n### TestImages.jl\r\n\r\nIn the initial phase of drafting my proposal, I had played around with Images.jl and TestImages.jl to understand the packages and try to make some initial contributions to the same. In the process, I felt that TestImages.jl needed a proper documentation along with a guide for contributing test images. Apart from the documentation, there was also a need to store the test images in a proper repository so that the links would not expire. Once my proposal was selected, I started working on this and with help from Tim Holy, I developed a new website for TestImages.jl along with an improved API to easily download images from the repository. The new API checks if the requested image is present in the online repository if it is not found locally and downloads it for the user.\r\n\r\nThe documentation can be viewed [here](https://timholy.github.io/TestImages.jl).\r\n\r\n### Histograms\r\n\r\nTo get familiar with open source and Images.jl, one of my first PRs was to add the histogram functionality. This was a very simple function which would calculate the histogram of an image i.e. the intensity distribution.\r\n\r\n```julia\r\nedges, count = imhist(img, nbins)\r\nedges, count = imhist(img, nbins, minval, maxval)\r\n```\r\nThis generates a histogram for the image over `nbins` spread between `(minval, maxval]`. If `minval` and `maxval` are not given, then the minimum and maximum values present in the image are taken. `edges` specifies the range of the bins while `count` is a vector of the individual counts of the bins.\r\n\r\n## Summary of Contributions\r\n| Package | Merged Commits | Pull Requests (Open and Merged) |\r\n|---------|----------------|---------------------------------|\r\n| [Images.jl](https://github.com/timholy/Images.jl) | [Link](https://github.com/timholy/Images.jl/commits/master?author=mronian) | [Link](https://github.com/timholy/Images.jl/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Amronian%20)\r\n| [ImageFeatures.jl](https://github.com/JuliaImages/ImageFeatures.jl) | [Link](https://github.com/JuliaImages/ImageFeatures.jl/commits/master?author=mronian) | [Link](https://github.com/JuliaImages/ImageFeatures.jl/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Amronian%20)\r\n| [ImageDraw.jl](https://github.com/JuliaImages/ImageDraw.jl) | [Link](https://github.com/JuliaImages/ImageDraw.jl/commits/master?author=mronian) | [Link](https://github.com/JuliaImages/ImageDraw.jl/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Amronian%20)\r\n| [TestImages.jl](https://github.com/timholy/TestImages.jl) | [Link](https://github.com/timholy/TestImages.jl/commits/master?author=mronian) | [Link](https://github.com/timholy/TestImages.jl/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Amronian%20)\r\n| [ColorVectorSpace.jl](https://github.com/JuliaGraphics/ColorVectorSpace.jl) | [Link](https://github.com/JuliaGraphics/ColorVectorSpace.jl/commits/master?author=mronian) | [Link](https://github.com/JuliaGraphics/ColorVectorSpace.jl/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Amronian%20)\r\n| [ColorTypes.jl](https://github.com/JuliaGraphics/ColorTypes.jl) | [Link](https://github.com/JuliaGraphics/ColorTypes.jl/commits/master?author=mronian) | [Link](https://github.com/JuliaGraphics/ColorTypes.jl/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Amronian%20)\r\n\r\n## Exposure Correction\r\n\r\nThe first part of my proposal was to add exposure correction functionality to Images.jl. This was a bit challenging considering the various type of Images and ColorTypes in julia and my goal was to provide a common API which would handle all types of Images using julia's method dispatch. I am happy to say that we were able to do this to a considerable extent and all the functions are easy to use and intuitive, offering a lot of options at the same time.\r\n\r\n### Histogram Equalisation\r\n\r\nMy first contribution during the coding period was the histogram equalisation functionality. This took up quite a bit of time as I worked on optimising the performance and got to learn about the inner workings of Arrays (Images are derived from Arrays!) in julia and how to write efficient functions for operating on them.  I was also introduced to `@code_warntype` and how to julia infers the type of variables in the code and how to best exploit this to increase performance. Tim Holy was really helpful and patient (Thanks Tim!) throughout the initial phase with a lot of code reviews and advice which really helped me later on.\r\n\r\n```julia\r\nhist_equalised_img = histeq(img, nbins)\r\nhist_equalised_img = histeq(img, nbins, minval, maxval)\r\n```\r\n\r\nThis returns a histogram equalised image with a granularity of approximately `nbins` number of bins. If `minval` and `maxval` are specified then intensities are equalized to the range `(minval, maxval)`. The default values are `0` and `1`.\r\n\r\n### Histogram Matching\r\n\r\nHistogram matching is another way of achieving exposure correction by trying to modify the histogram of the image to match that of a predefined image with the desired histogram.\r\n\r\n```julia\r\nhist_matched_img = histmatch(img, oimg, nbins)\r\n```\r\n\r\nThis returns a grayscale histogram matched image with a granularity of `nbins` number of bins. `img` is the image to be matched and `oimg` is the image having the desired histogram to be matched to.\r\n\r\n### Gamma Correction\r\n\r\nGamma correction is a method of enhancing or reducing the intensity levels in an image by using a power function.\r\n\r\n```julia\r\ngamma_corrected_img = adjust_gamma(img, gamma)\r\n```\r\n\r\nThe `adjust_gamma` function can handle a variety of input types. The returned image depends on the input type. If the input is an `Image` then the resulting image is of the same type and has the same properties.\r\n\r\n### Contrast Limited Adaptive Histogram Equalisation\r\n\r\nAn advanced version of histogram equalisation, it differs from ordinary histogram equalization in the respect that the adaptive method computes several histograms, each corresponding to a distinct section of the image, and uses them to redistribute the lightness values of the image. It is therefore suitable for improving the local contrast and enhancing the definitions of edges in each region of an image.\r\n\r\nIn the straightforward form, CLAHE is done by calculation a histogram of a window around each pixel and using the transformation function of the equalised histogram to rescale the pixel. Since this is computationally expensive, we use interpolation which gives a significant rise in efficiency without compromising the result. The image is divided into a grid and equalised histograms are calculated for each block. Then, each pixel is interpolated using the closest histograms.\r\n\r\n```julia\r\nhist_equalised_img = clahe(img, nbins, xblocks = 8, yblocks = 8, clip = 3)\r\n```\r\n\r\nThe `xblocks` and `yblocks` specify the number of blocks to divide the input image into in each direction. `nbins` specifies the granularity of histogram calculation of each local region. `clip` specifies the value at which the histogram is clipped. The excess in the histogram bins with value exceeding `clip` is redistributed among the other bins.\r\n\r\n## Feature Extraction\r\n\r\nAfter working on exposure correction, I began with the other major chunk of my proposal which was ImageFeatures.jl. Edge and corner detection was already a part of Images.jl so I added some of my work in the same to Images.jl itself (this will be moved to ImageFeatures.jl before release). \r\n\r\n### Canny Edge Detection\r\n\r\nThe canny edge detector works by finding intensity gradients of an image and then double thresholding pixels as being part of weak or strong edges. Then the weak edges not connected to any strong edge are discarded and the result has the edges detected in the image.\r\n\r\n```julia\r\ncanny_edges = canny(img, sigma = 1.4, upperThreshold = 0.80, lowerThreshold = 0.20)\r\n```\r\n\r\n### Corner Detection\r\n\r\nI worked on the `imcorner` API to overhaul the existing corner detection functions and added additional functionality with \r\n`kitchen_rosenfeld` corners and FAST corners (discussed below). \r\n\r\n```julia\r\ncorners = imcorner(img; [method])\r\ncorners = imcorner(img, threshold, percentile; [method])\r\n```\r\n\r\nThe `method` argument takes in the name of the algorithm to be used to detect corners, namely `harris`, `shi_tomasi` and `kitchen_rosenfeld`.\r\n\r\n### FAST Corners\r\n\r\nFAST (Features from Accelerated Segment Test) corners, an efficient and very popular corner detection algorithm works by finding a contiguous set of pixels brighter or darker than the candidate pixel. Depending on the number of contiguous pixels found, the candidate is marked as a potential corner. \r\n\r\nFAST corners may be detected by using the `fastcorners` API.\r\n\r\n```julia\r\ncorners = fastcorners(img, n, threshold)\r\n```\r\n\r\n### ImageFeatures.jl\r\n\r\nI started work on ImageFeatures.jl by adding texture matching descriptors like GLCMs (Gray Level Co-occurence Matrix) and LBPs (Local Binary Patterns). \r\n\r\n### Gray Level Co Occurence Matrices\r\n\r\nGray Level Co-occurrence Matrix (GLCM) is used for texture analysis. We consider two pixels at a time, called the reference and the neighbour pixel. We define a particular spatial relationship between the reference and neighbour pixel before calculating the GLCM.\r\n\r\nThe GLCM is calculated by calling one of `glcm`, `glcm_symmetric` or `glcm_norm` functions depending on the desired GLCM type. \r\n\r\n```julia\r\nglcm = glcm(img, distance, angle, mat_size)\r\n```\r\n\r\nIf multiple GLCMs need to be calculated, the same function may be used by passing a vector in the arguments. The `distance` and `angle` arguments take in both `Int` and `Vector{Int}` values.\r\n\r\nMultiple properties of the obtained GLCM can be calculated by using the `glcm_prof` function which calculates the property of the entire matrix or in windows if given the window dimensions.\r\n\r\n```julia\r\nprop = glcm_prop(glcm, property)\r\nprop = glcm_prop(glcm, height, width, property)\r\n```\r\n\r\nVarious properties can be calculated like `mean`, `variance`, `correlation`, `contrast`, `IDM` (Inverse Difference Moment), `ASM` (Angular Second Moment), `entropy`, `max_prob` (Max Probability), `energy` and `dissimilarity`.\r\n\r\n### Local Binary Patterns\r\n\r\nLocal Binary Pattern (LBP) is a very efficient texture operator which labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number. The feature vector can now then be processed using some machine-learning algorithm to classify images. Such classifiers are often used for face recognition or texture analysis.\r\n\r\nWe have multiple type of LBP algorithms in ImageFeatures.jl :\r\n\r\nThe first three methods can be used with both circular offsets (circle around the pixel) or the 8x8 neighbourhood.\r\n\r\nThe first two methods, `lbp` and `modified_lbp` may be called with one of three `lbp_original`, `lbp_uniform` and `lbp_rotation_invariant` as the `method` argument which specifies the method used to create the bit pattern.\r\n\r\n- `lbp` is the original algorithm defined in the `94 paper.\r\n- `modified_lbp` is a version of LBP which compares the intensity of each pixel with the average intensity in the window.\r\n- `direction_coded_lbp` is a version of LBP where the intensity differences along the four directions (N-S, NW-SE, NE-SW, E-W) are coded along with the variation in differences along the directions in 8 bits.\r\n- `multi_block_lbp` is a version of LBP used for window matching as an alternative to Haar like features. The image is divided into blocks and the average intensity of each block is considered with the center block to obtain the LBP.\r\n\r\n```julia\r\nlbp_image = lbp(img)\r\nlbp_image = lbp(img, 10, 2) # With circular offsets\r\nlbp_image = lbp(img_gray, lbp_uniform)\r\nlbp_image = lbp(img_gray, lbp_rotation_invariant)\r\n\r\n\r\nlbp_image = modified_lbp(img_gray)\r\nlbp_image = modified_lbp(img_gray, points, radius)\r\n\r\nlbp_image = direction_coded_lbp(img)\r\nlbp_image = direction_coded_lbp(img, points, radius)\r\n\r\npattern = multi_block_lbp(img, top_left_y, top_left_x, height_block, width_block)\r\n```\r\n\r\nWe can also create the descriptor from a histogram of LBPs over the image by calling `create_descriptor`.\r\n\r\n```julia\r\ndesc = create_descriptor(img, yblocks, xblocks, [lbp_type])\r\n```\r\n\r\nThe `lbp_type` argument takes in one of the functions defined above, while the `yblocks` and `xblocks` arguments specify the size of the grid to create in the image.\r\n\r\n### Framework\r\n\r\nBefore starting with the feature descriptors, we decided on a easy to use common API which could be used with all the algorithms. \r\n\r\nThe `Feature` and `Keypoint` types are the fundamental types in ImageFeatures.jl. `Feature` stores the `keypoint` and its `orientation` and `scale`. A vector of the `Feature` type is denoted by the `Features` type and similary a vector of `Keypoint` type is denoted by the `Keypoints` type. We provide multiple methods for easily transitioning between the two types. \r\n\r\n`Keypoints` or `Features` can be generate from an image of boolean values by `Keypoints(boolean_image)` or `Features(boolean_image)` where the boolean_image may be obtained from a feature detection algorithm for eg. the result of a corner detector. All feature detectors in ImageFeatures.jl directly return `Features`.\r\n\r\nA keypoint may be converted to a feature or vice versa by directly passing it to the respective method eg. `Keypoint(feature_A)` or `Feature(keypoint_A)`.\r\n\r\nThe algorithms in ImageFeatures.jl are to be used by calling the `extract_features` and `create_descriptor` APIs.\r\n\r\n```julia\r\nkeypoints = extract_features(img, params)\r\n```\r\n\r\nThe `params` argument is dependent on the algorithm chosen and its type is the name of the algorithm. For eg. `censure_params <: CENSURE`\r\n\r\n```julia\r\ndescriptor, ret_keypoints = create_descriptor(img, params)\r\ndescriptor, ret_keypoints = create_descriptor(img, keypoints, params)\r\n```\r\n\r\nDepending on the algorithm , the `create_descriptor` API can be used to directly create a feature descriptor from the image (eg. ORB, BRISK) or from the keypoints (eg. BRIEF, FREAK). In case of the latter, the keypoints can be obtained using algorithms such as FAST or CENSURE. The `params` argument is dependent on the algorithm chosen and its type is the name of the algorithm. For eg. `brief_params <: BRIEF`\r\n\r\nA brief discussion on the various algorithms is given below. For more details on each of the algorithms and the parameters of the constructor methods, please visit the [documentation](http://juliaimages.github.io/ImageFeatures.jl/latest/) for ImageFeatures.jl.\r\n\r\n### BRIEF Descriptors\r\n\r\nBRIEF (Binary Robust Independent Elementary Features) is an efficient feature point descriptor. It is highly discriminative even when using relatively few bits and is computed using simple intensity difference tests. BRIEF does not have a predefined sampling pattern and the pairs are chosen randomly.\r\n\r\n```julia\r\nbrief_params = BRIEF([size], [window], [sigma], [sampling_type], [seed])\r\ndesc, ret_keypoints = create_descriptor(img, keypoints, brief_params)\r\n```\r\n\r\n### ORB Keypoints and Descriptors\r\n\r\nORB (Oriented Fast and Rotated Brief) descriptor is similar to BRIEF but has an orientation detection mechanism. Apart from creating a descriptor, it also extracts keypoints over a gaussian pyramid using the FAST corners algorithm.\r\n\r\nIt can be used by calling the ORB constructor method. \r\n\r\n```julia\r\norb_params = ORB([num_keypoints], [n_fast], [threshold], [harris_factor], [downsample], [levels], [sigma])\r\ndesc, ret_keypoints = create_descriptor(img, orb_params)\r\n```\r\n\r\n### CENSURE Keypoints\r\n\r\n*Note : This PR is still open. The function needs more tests before it can be merged.*\r\n\r\nCENSURE (CENter SURround Extremas) keypoints are calculated using extremas at all scales and locations unlike SIFT or SURF which take extremas at each octave. To approximate the Laplacian operator, a bi-level (1 or -1) centre surround filter is used. Increasing size of the filter in each octave gives the result of the operator at different scales. Points of maxima and minima across the octaves are extracted as keypoints.\r\n\r\n```julia\r\ncensure_params = CENSURE([smallest], [largest], [filter], [response_threshold], [line_threshold])\r\nkeypoints = extract_features(img, censure_params)\r\n```\r\n\r\n### BRISK Descriptors\r\n\r\nThe BRISK (Binary Robust Invariant Scalable Keypoints) descriptor has a predefined sampling pattern as compared to BRIEF or ORB. Pixels are sampled over concentric rings. \r\n\r\nThe BRISK descriptor can be used by calling the BRISK constructor method to define the parameters and then using it with the `create_descriptor` API. \r\n\r\n```julia\r\nbrisk_params = BRISK([pattern_scale])\r\ndesc, ret_keypoints = create_descriptor(img, keypoints, brisk_params)\r\n```\r\n\r\n### FREAK Descriptors\r\n\r\nThe FREAK (Fast REtinA Keypoint) descriptor, similar to BRISK as a predefined sampling pattern. It uses a retinal sampling grid with more density of points near the centre with the density decreasing exponentially with distance from the centre.\r\n\r\nThe FREAK descriptor can be used by calling the FREAK constructor method to define the parameters and then using it with the `create_descriptor` API. Unlike BRISK, FREAK does not calculate the keypoints.\r\n\r\n```julia\r\nfreak_params = FREAK([pattern_scale])\r\ndesc, ret_keypoints = create_descriptor(img, keypoints, freak_params)\r\n```\r\n\r\n## ImageDraw.jl\r\n\r\nTo help me understand how the feature detection algorithms were working, I needed a drawing library for Images in julia. Since it was already on the roadmap for JuliaImages, I developed proper APIs and created a new package, [ImageDraw.jl](https://github.com/JuliaImages/ImageDraw.jl). \r\n\r\n### Lines\r\n\r\nThe `line` and `line!` functions draw a line on the input image given the points p1, p2 as CartesianIndex{2} with the given `color`. Lines are drawn using the `bresenham` method by default. If anti-aliasing is required, the `xiaolin_wu` can be used. \r\n\r\n```julia\r\nimg_with_line = line(img, p1, p2, color, method)\r\nimg_with_line = line(img, y0, x0, y1, x1, color, method)\r\n```\r\n\r\nTo draw a line on the input image itself, use the line! function.\r\n\r\n```julia\r\nline!(img, p1, p2, color, method)\r\n```\r\n\r\n### Circles and Ellipses\r\n\r\nThe `ellipse` and `ellipse!` (similar use as `line!`) draw an ellipse on the input image given the `center` as a `CartesianIndex{2}` or as coordinates `(y, x)` using the specified `color`. If `color` is not specified, `one(eltype(img))` is used.\r\n\r\n```julia\r\nimg_with_ellipse = ellipse(img, center, radiusy, radiusx)\r\nimg_with_ellipse = ellipse(img, center, color, radiusy, radiusx)\r\nimg_with_ellipse = ellipse(img, y, x, radiusy, radiusx)\r\nimg_with_ellipse = ellipse(img, y, x, color, radiusy, radiusx)\r\n```\r\n\r\nSimilarly the `circle` and its counterpart `circle!` functions may be used to draw circles.\r\n\r\n```julia\r\nimg_with_circle = circle(img, center, radiusy, radiusx)\r\nimg_with_circle = circle(img, center, color, radiusy, radiusx)\r\nimg_with_circle = circle(img, y, x, radiusy, radiusx)\r\nimg_with_circle = circle(img, y, x, color, radiusy, radiusx)\r\n```\r\n\r\n## Miscellaneous\r\n\r\nApart from the work discussed above, I also made minor contributions to two related packages, [ColorVectorSpace.jl](https://github.com/JuliaGraphics/ColorVectorSpace.jl) and [ColorTypes.jl](https://github.com/JuliaGraphics/ColorTypes.jl)\r\n\r\n## Future Work\r\n\r\nThe BRISK and CENSURE PRs are yet to be merged. The BRISK PR is currently under review while the CENSURE one needs more tests before it can be merged. I hope to finish them before the GSoC period ends.\r\n\r\nI am also working on creating a set of tutorials on extracting features and using them to match images. The link to the tutorials can be found at the ImageFeatures.jl documentation [website](http://juliaimages.github.io/ImageFeatures.jl/latest).\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}